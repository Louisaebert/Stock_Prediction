{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "- [01 Importing Moduls](#01-Importing-Moduls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 Importing Moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as sia\n",
    "from gensim.parsing.preprocessing import STOPWORDS, strip_tags, strip_numeric, strip_punctuation, strip_multiple_whitespaces, remove_stopwords, strip_short, stem_text\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf # This code has been tested with TensorFlow 1.6\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('bmh')\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this case: Zoom\n",
    "\n",
    "data=yf.download(\"SPY AAPL\", start=\"2017-01-01\", end=\"2017-04-30\",threads= False)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3a4206df7ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#data.drop(\"Date\", inplace=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data['datetime']=data.index\n",
    "data.reset_index()\n",
    "#data.drop(\"Date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-304fa4ce4ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ta # for getting financial indicators \n",
    "from ta import add_all_ta_features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_all_ta_features(\n",
    "    data, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\", fillna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,8])\n",
    "plt.plot(data.datetime,data.Open)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Zoom Opening Stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install finnhub-python\n",
    "#!pip install pystan==2.19.1.1.\n",
    "#!pip install  prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import finnhub\n",
    "\n",
    "# Setup client\n",
    "finnhub_client = finnhub.Client(api_key=\"c2si65iad3ic1qis06lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(company, date_from='2020-01-01', date_to=None):\n",
    "    '''\n",
    "    returns dataframe with average sentiment of news headline and sentiment of news summary for every date in a given timeframe\n",
    "    company: symbol, example ZM\n",
    "    date_from: string format yyyy-mm-dd\n",
    "    date_to: string format yyyy-mm-dd\n",
    "    '''\n",
    "    sid_obj = sia()\n",
    "    if date_to is None:\n",
    "        date_to = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "    result=(finnhub_client.company_news(company, _from=date_from, to=date_to))\n",
    "    news_df = pd.DataFrame(result)\n",
    "    news_df['datetime'] = [datetime.datetime.utcfromtimestamp(i).strftime('%Y-%m-%d') for i in news_df.datetime]\n",
    "    news_df.drop(['id','image', 'related','source', 'url'], axis=1, inplace=True)\n",
    "    news_df['headline_sentiment'] = [sid_obj.polarity_scores(c)['compound'] for c in news_df['headline']]\n",
    "    news_df['summary_sentiment'] = [sid_obj.polarity_scores(c)['compound'] for c in news_df['summary']]\n",
    "    news_dates = news_df.groupby(['datetime']).mean().sort_index().reset_index()\n",
    "    return news_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dates=get_news(\"ZM\", date_from='2020-01-01')\n",
    "#news_dates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dates['datetime']=news_dates['datetime'].astype('datetime64[ns]')#datetime64\n",
    "data['datetime']=data['datetime'].astype('datetime64[ns]')\n",
    "df=news_dates.merge(data,on=\"datetime\",how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dates.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot=df[df.datetime > '2021-03-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[30,8])\n",
    "x1 = df_plot.datetime\n",
    "y1 = df_plot.Open\n",
    "# plotting the line 1 points \n",
    "plt.plot(x1, y1, label = \"line 1\")\n",
    "# line 2 points\n",
    "x2 = df_plot.datetime\n",
    "y2 = df_plot.headline_sentiment*100\n",
    "# plotting the line 2 points \n",
    "plt.plot(x2, y2, label = \"line 2\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.xlabel('x - axis')\n",
    "# Set the y axis label of the current axis.\n",
    "plt.ylabel('y - axis')\n",
    "# Set a title of the current axes.\n",
    "plt.title('Two or more lines on same plot with suitable legends ')\n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    "# Display a figure.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest for Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shifting \n",
    "move_days = 7\n",
    "# shifted values column, like this the model can learn what the price is going to be x days later\n",
    "df[\"shift_close\"]=df[[\"Close\"]].shift(-move_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x without the NaNs \n",
    "X = np.array(df.drop(['shift_close','datetime'],1))[:-move_days]\n",
    "X = np.array(df.drop(['shift_close','datetime'],1))[:-move_days]\n",
    "y = df.shift_close[:-move_days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to make this work somehow\n",
    "#X= SelectKBest(f_regression, k=20).fit_transform(X, y)\n",
    "#X = X[:-move_days]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a model on the dataset where we have all data\n",
    "param_grid = {'min_samples_leaf': [2,3,5,10,20], 'n_estimators': [3,5,10,50,100]}\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 10)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor(min_samples_leaf=2, n_estimators=3, random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_existing=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(y_test, y_pred_existing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the X variable is going to be the features for the days where we have no \"in x Days price\"\n",
    "X_pred=df.drop(['shift_close','datetime'],1)[:-move_days]\n",
    "X_pred=X_pred.tail(move_days)\n",
    "#X_pred=np.array(X_pred)\n",
    "#print(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values for the next 7 days \n",
    "pred=rf.predict(X_pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred=pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pred=[]\n",
    "for i in range (1,move_days):\n",
    "    date_pred.append(df.datetime.iloc[-1]+timedelta(days=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pred.todatetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,move_days):\n",
    "    df_pred['pred_date']=df.datetime.iloc[-1]+timedelta(days=i)\n",
    "    df_pred.pred_date.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test,feature_names=X_test.columns,max_display=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame(rf.feature_importances_, index=X_pred.columns, columns=['feature importance']).sort_values('feature importance', ascending=False)\n",
    "print(df_feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,move_days+1,1),pred)\n",
    "plt.xlabel(\"Days from now\")\n",
    "plt.ylabel(\"Price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to think of a way to plot this nicely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook Prophet on Close Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FB Prophet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "from prophet.plot import plot_plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)\n",
    "df_train = data[['datetime','Close']]\n",
    "df_train = df_train.rename(columns={\"datetime\": \"ds\", \"Close\": \"y\"})\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet(interval_width=0.95)\n",
    "m.fit(df_train)\n",
    "future = m.make_future_dataframe(periods=21, freq ='D')\n",
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot(forecast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model (code should be correct, but somethings wrong with the package) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "new_data = data[['datetime','Close']]\n",
    "for i in range(0,len(data)):\n",
    "    new_data['datetime'][i] = data['datetime'][i]\n",
    "    new_data['Close'][i] = data['Close'][i]\n",
    "\n",
    "#setting index\n",
    "new_data.index = new_data.datetime\n",
    "new_data.drop('datetime', axis=1, inplace=True)\n",
    "\n",
    "#creating train and test sets\n",
    "dataset = new_data.values\n",
    "\n",
    "train = dataset[0:274,:]\n",
    "valid = dataset[274:,:]\n",
    "\n",
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(60,len(train)):\n",
    "    x_train.append(scaled_data[i-60:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2)\n",
    "\n",
    "#predicting 246 values, using past 60 from the train data\n",
    "inputs = new_data[len(new_data) - len(valid) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = scaler.inverse_transform(closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
